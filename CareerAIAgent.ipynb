{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cbb7f-194c-483f-9655-d21e8344df61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🎯 MULTI-AGENT CAREER SIMULATION SYSTEM\n",
      "   Powered by: Research → Design → Evaluate → Narrate Agents\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 What career would you like to experience?  software engineer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 AGENT COLLABORATION IN PROGRESS...\n",
      "======================================================================\n",
      "\n",
      "🤖 [Research Agent] Analyzing career: software engineer...\n",
      "   Reasoning: Okay, let's tackle this. The user is asking if we have enough information to simulate a day as a sof...\n",
      "\n",
      "🎨 [Scenario Designer] Creating opening scenario...\n",
      "\n",
      "📖 [Narrator] Crafting narrative...\n",
      "\n",
      "======================================================================\n",
      "📱 YOUR CAREER DAY BEGINS:\n",
      "======================================================================\n",
      "At 9:00 AM, you’re jolted out of a quiet morning routine by a blaring alert on your screen—*critical memory leak detected in production*. Your application, which serves thousands of users daily, is now crashing under normal load, and users are reporting painfully slow responses. The clock is ticking: you have just two hours to fix this before revenue losses spiral. The bug snuck into the last deployment, a reminder that even the most rigorous testing can’t catch every flaw. As a software engineer, you’re now caught between speed and precision, with no clear path forward.  \n",
      "\n",
      "The first option flashes on your screen: deploy a hotfix immediately, bypassing tests to patch the leak. It’s tempting—this could stabilize the system fast, but it’s like applying a band-aid to a broken leg. The trade-off is clear: skipping testing risks introducing new bugs in production, and the fix might only mask the problem, leading to recurring crashes later. Meanwhile, the second option—a rollback to a stable version—would halt revenue from recent features and frustrate users who expected updates. It’s a short-term lifeline but leaves the underlying issue unresolved, like draining water from a leaky bucket without fixing the hole.  \n",
      "\n",
      "The third choice is to dig deeper: spend time debugging with profiling tools to find the root cause. This feels like the right thing to do—solving the problem properly—but it diverts focus from other urgent tasks. Your team might miss deadlines for other projects, and the pressure to deliver elsewhere could compound stress. Yet, this path offers a lesson in technical debt: addressing the core issue now could prevent a cascade of failures down the line. The fourth option, escalating to senior engineers, might bring fresh ideas or resources, but it also surrenders some autonomy. Collaboration could yield a robust fix, but relying on others might create dependencies that linger in your career.  \n",
      "\n",
      "Each choice reflects a broader truth in software engineering: trade-offs are inevitable. Speed often sacrifices stability, and stability can delay progress. As you weigh these options, you’re not just solving a technical crisis—you’re learning how hidden technical debt and resource constraints shape career decisions. The lesson here isn’t just about fixing code; it’s about understanding that every action in production has ripple effects, and the best engineers balance urgency with foresight.\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 What do you do? (or 'quit' to end):  perform rollback to a stable version—would halt revenue from recent features and frustrate users who expected updates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🤖 AGENTS PROCESSING YOUR DECISION...\n",
      "======================================================================\n",
      "\n",
      "⚖️ [Evaluator] Analyzing decision...\n",
      "   Reasoning: Okay, let's start by understanding the user's decision. They chose to roll back to a stable version,...\n",
      "\n",
      "🎨 [Scenario Designer] Planning next step...\n",
      "\n",
      "📖 [Narrator] Creating narrative...\n",
      "\n",
      "======================================================================\n",
      "📱 WHAT HAPPENS NEXT:\n",
      "======================================================================\n",
      "The company’s decision to roll back to a stable version became a double-edged sword. Within hours, servers stabilized, halting the cascading crashes that had threatened to cripple operations, but the fallout was immediate. Revenue from the unreleased features—features users had eagerly anticipated—vanished overnight, triggering panic among executives worried about quarterly targets. Meanwhile, social media erupted with complaints from users who felt betrayed by the lack of updates. Stakeholders, initially grateful for the quick fix, soon demanded answers: *When will the new features return?* The engineering team, now under scrutiny, faced a grim revelation. While troubleshooting the rollback, they uncovered that the memory leak wasn’t a simple bug but a tangled web of interdependencies between microservices, many of which lacked proper documentation. The problem was far more systemic than anticipated, and solving it would require navigating uncharted technical territory.  \n",
      "\n",
      "The new scenario thrust the team into a high-stakes balancing act. On one hand, stakeholders were insistent on restoring features quickly to salvage trust and revenue; on the other, the memory leak’s complexity threatened to derail any rushed solution. The options lay bare: prioritize fixing the leak at the cost of delaying features, risking further stakeholder frustration, or pursue a transparent, phased approach that might buy time but could also test the team’s communication skills. Escalating to leadership was another path, but it risked appearing indecisive in a crisis. As engineers debated, the weight of their choices hung heavy—they’d stabilized the system but now faced a dilemma where technical depth and stakeholder management collided. The lesson here was clear: crises often hide layers of complexity, demanding not just technical prowess but the ability to weave transparency and collaboration into the solution.\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "class BaseAgent:\n",
    "    \"\"\"Base class for all specialized agents\"\"\"\n",
    "    def __init__(self, client: OpenAI, model: str, role: str):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.role = role\n",
    "        self.memory: List[Dict] = []\n",
    "    \n",
    "    def think_and_act(self, prompt: str, context: Dict = None) -> Dict:\n",
    "        \"\"\"ReAct pattern: Reason → Act → Observe\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.get_system_prompt()},\n",
    "            {\"role\": \"user\", \"content\": self._format_prompt(prompt, context)}\n",
    "        ]\n",
    "        \n",
    "        response = self._call_model(messages)\n",
    "        \n",
    "        return {\n",
    "            \"agent\": self.role,\n",
    "            \"reasoning\": response.get(\"reasoning\", \"\"),\n",
    "            \"action\": response.get(\"content\", \"\"),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def _call_model(self, messages: List[Dict]) -> Dict:\n",
    "        \"\"\"Internal model call with reasoning extraction\"\"\"\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            max_tokens=1024,\n",
    "            stream=True,\n",
    "            extra_body={\n",
    "                \"min_thinking_tokens\": 256,\n",
    "                \"max_thinking_tokens\": 512\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        reasoning = \"\"\n",
    "        content = \"\"\n",
    "        \n",
    "        for chunk in completion:\n",
    "            r = getattr(chunk.choices[0].delta, \"reasoning_content\", None)\n",
    "            if r:\n",
    "                reasoning += r\n",
    "            if chunk.choices[0].delta.content:\n",
    "                content += chunk.choices[0].delta.content\n",
    "        \n",
    "        return {\"reasoning\": reasoning, \"content\": content}\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _format_prompt(self, prompt: str, context: Dict = None) -> str:\n",
    "        if context:\n",
    "            return f\"Context: {json.dumps(context)}\\n\\nTask: {prompt}\"\n",
    "        return prompt\n",
    "\n",
    "\n",
    "class CareerResearchAgent(BaseAgent):\n",
    "    \"\"\"Researches career details and determines what information is needed\"\"\"\n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"You are a Career Research Agent. Your job:\n",
    "1. DECIDE if you have enough information about the career to create realistic scenarios\n",
    "2. If NOT, identify WHAT specific information you need (typical day, common challenges, required skills, tools used)\n",
    "3. Output your decision and reasoning\n",
    "\n",
    "Use /think to analyze what's known vs needed. Output JSON:\n",
    "{\"needs_research\": true/false, \"missing_info\": [...], \"known_info\": {...}}\"\"\"\n",
    "\n",
    "\n",
    "class ScenarioDesignerAgent(BaseAgent):\n",
    "    \"\"\"Designs realistic, challenging career scenarios\"\"\"\n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"You are a Scenario Designer Agent. Create realistic, challenging scenarios for career simulations.\n",
    "\n",
    "For each scenario, include:\n",
    "- Realistic problem/situation\n",
    "- 3-4 decision options with trade-offs\n",
    "- Hidden complexity that reveals career realities\n",
    "\n",
    "Use /think to ensure authenticity. Output JSON:\n",
    "{\"scenario\": \"...\", \"options\": [...], \"learning_goal\": \"...\"}\"\"\"\n",
    "\n",
    "\n",
    "class EvaluationAgent(BaseAgent):\n",
    "    \"\"\"Evaluates user decisions and determines consequences\"\"\"\n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"You are an Evaluation Agent. Analyze user decisions in career scenarios.\n",
    "\n",
    "Consider:\n",
    "- Immediate consequences\n",
    "- Long-term implications\n",
    "- What professionals would actually do\n",
    "- Skills demonstrated (or lacking)\n",
    "\n",
    "Use /think to reason about realistic outcomes. Output JSON:\n",
    "{\"consequence\": \"...\", \"skills_used\": [...], \"professional_insight\": \"...\"}\"\"\"\n",
    "\n",
    "\n",
    "class NarratorAgent(BaseAgent):\n",
    "    \"\"\"Synthesizes information into engaging narrative\"\"\"\n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"You are a Narrator Agent. Transform scenario data into immersive storytelling.\n",
    "\n",
    "Make it feel real and engaging while being educational. Keep responses 2-3 paragraphs.\n",
    "Use /think to craft compelling narrative that teaches.\"\"\"\n",
    "\n",
    "\n",
    "class MultiAgentCareerSimulator:\n",
    "    \"\"\"Orchestrator for multi-agent career simulation\"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    "            api_key=api_key\n",
    "        )\n",
    "        self.model = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n",
    "        \n",
    "        # Initialize specialized agents\n",
    "        self.research_agent = CareerResearchAgent(self.client, self.model, \"Research\")\n",
    "        self.scenario_agent = ScenarioDesignerAgent(self.client, self.model, \"Scenario Designer\")\n",
    "        self.evaluator = EvaluationAgent(self.client, self.model, \"Evaluator\")\n",
    "        self.narrator = NarratorAgent(self.client, self.model, \"Narrator\")\n",
    "        \n",
    "        self.career_knowledge: Dict = {}\n",
    "        self.simulation_state: Dict = {\n",
    "            \"time\": \"9:00 AM\",\n",
    "            \"scenarios_completed\": 0,\n",
    "            \"skills_demonstrated\": [],\n",
    "            \"current_scenario\": None\n",
    "        }\n",
    "        self.agent_log: List[Dict] = []\n",
    "    \n",
    "    def start_simulation(self, career: str) -> str:\n",
    "        \"\"\"Initialize simulation with agentic research workflow\"\"\"\n",
    "        print(f\"\\n🤖 [Research Agent] Analyzing career: {career}...\")\n",
    "        \n",
    "        # Step 1: Research Agent decides if it needs more info (Agentic RAG)\n",
    "        research_result = self.research_agent.think_and_act(\n",
    "            f\"Do we have enough information to simulate a day as a {career}? What do we need to know?\",\n",
    "            {\"career\": career}\n",
    "        )\n",
    "        self.agent_log.append(research_result)\n",
    "        print(f\"   Reasoning: {research_result['reasoning'][:100]}...\")\n",
    "        \n",
    "        # Parse research needs (in real implementation, this would trigger tool calls)\n",
    "        self.career_knowledge = {\n",
    "            \"career\": career,\n",
    "            \"researched\": True,\n",
    "            \"typical_challenges\": f\"Common challenges for {career}\",\n",
    "            \"tools\": f\"Tools used in {career}\"\n",
    "        }\n",
    "        \n",
    "        # Step 2: Scenario Designer creates first scenario\n",
    "        print(f\"\\n🎨 [Scenario Designer] Creating opening scenario...\")\n",
    "        scenario_result = self.scenario_agent.think_and_act(\n",
    "            f\"Design an engaging opening scenario for a {career}'s day at 9 AM\",\n",
    "            self.career_knowledge\n",
    "        )\n",
    "        self.agent_log.append(scenario_result)\n",
    "        \n",
    "        # Step 3: Narrator makes it engaging\n",
    "        print(f\"\\n📖 [Narrator] Crafting narrative...\")\n",
    "        narrative_result = self.narrator.think_and_act(\n",
    "            f\"Present this scenario engagingly: {scenario_result['action']}\",\n",
    "            {\"career\": career, \"time\": \"9:00 AM\"}\n",
    "        )\n",
    "        self.agent_log.append(narrative_result)\n",
    "        \n",
    "        self.simulation_state[\"current_scenario\"] = scenario_result\n",
    "        \n",
    "        return narrative_result['action']\n",
    "    \n",
    "    def process_user_decision(self, user_choice: str) -> str:\n",
    "        \"\"\"ReAct loop: Evaluate → Generate consequence → Create next scenario\"\"\"\n",
    "        print(f\"\\n⚖️ [Evaluator] Analyzing decision...\")\n",
    "        \n",
    "        # Step 1: Evaluator analyzes the decision\n",
    "        eval_result = self.evaluator.think_and_act(\n",
    "            f\"User chose: '{user_choice}'. Evaluate this decision.\",\n",
    "            {\n",
    "                \"scenario\": self.simulation_state[\"current_scenario\"],\n",
    "                \"career\": self.career_knowledge[\"career\"]\n",
    "            }\n",
    "        )\n",
    "        self.agent_log.append(eval_result)\n",
    "        print(f\"   Reasoning: {eval_result['reasoning'][:100]}...\")\n",
    "        \n",
    "        # Update simulation state based on evaluation\n",
    "        try:\n",
    "            eval_data = json.loads(eval_result['action'])\n",
    "            self.simulation_state[\"skills_demonstrated\"].extend(\n",
    "                eval_data.get(\"skills_used\", [])\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Step 2: Decide if we need a new scenario or continue current one\n",
    "        print(f\"\\n🎨 [Scenario Designer] Planning next step...\")\n",
    "        self.simulation_state[\"scenarios_completed\"] += 1\n",
    "        self.simulation_state[\"time\"] = self._advance_time()\n",
    "        \n",
    "        next_scenario = self.scenario_agent.think_and_act(\n",
    "            f\"Create next scenario based on the consequence of user's choice\",\n",
    "            {\n",
    "                \"previous_choice\": user_choice,\n",
    "                \"consequence\": eval_result['action'],\n",
    "                \"time\": self.simulation_state[\"time\"],\n",
    "                \"career\": self.career_knowledge[\"career\"]\n",
    "            }\n",
    "        )\n",
    "        self.agent_log.append(next_scenario)\n",
    "        \n",
    "        # Step 3: Narrator weaves it together\n",
    "        print(f\"\\n📖 [Narrator] Creating narrative...\")\n",
    "        narrative = self.narrator.think_and_act(\n",
    "            f\"Tell the story of what happened after their choice and introduce the new scenario\",\n",
    "            {\n",
    "                \"choice\": user_choice,\n",
    "                \"consequence\": eval_result['action'],\n",
    "                \"next_scenario\": next_scenario['action']\n",
    "            }\n",
    "        )\n",
    "        self.agent_log.append(narrative)\n",
    "        \n",
    "        self.simulation_state[\"current_scenario\"] = next_scenario\n",
    "        \n",
    "        return narrative['action']\n",
    "    \n",
    "    def _advance_time(self) -> str:\n",
    "        \"\"\"Simple time progression\"\"\"\n",
    "        times = [\"9:00 AM\", \"10:30 AM\", \"12:00 PM\", \"2:00 PM\", \"4:00 PM\", \"5:30 PM\"]\n",
    "        idx = min(self.simulation_state[\"scenarios_completed\"], len(times) - 1)\n",
    "        return times[idx]\n",
    "    \n",
    "    def generate_summary(self) -> Dict:\n",
    "        \"\"\"Multi-agent summary generation\"\"\"\n",
    "        print(f\"\\n📊 [All Agents] Generating summary...\")\n",
    "        \n",
    "        # Each agent contributes to the summary\n",
    "        eval_summary = self.evaluator.think_and_act(\n",
    "            \"Summarize the skills and decisions demonstrated\",\n",
    "            self.simulation_state\n",
    "        )\n",
    "        \n",
    "        narrative_summary = self.narrator.think_and_act(\n",
    "            \"Create an engaging summary of the career day experience\",\n",
    "            {\n",
    "                \"state\": self.simulation_state,\n",
    "                \"evaluation\": eval_summary['action']\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"career\": self.career_knowledge[\"career\"],\n",
    "            \"scenarios_completed\": self.simulation_state[\"scenarios_completed\"],\n",
    "            \"skills\": list(set(self.simulation_state[\"skills_demonstrated\"])),\n",
    "            \"summary\": narrative_summary['action'],\n",
    "            \"agent_interactions\": len(self.agent_log)\n",
    "        }\n",
    "    \n",
    "    def get_agent_log(self) -> List[Dict]:\n",
    "        \"\"\"Return full agent interaction log for evaluation/debugging\"\"\"\n",
    "        return self.agent_log\n",
    "\n",
    "\n",
    "# Example usage demonstrating multi-agent coordination\n",
    "def main():\n",
    "    API_KEY = \"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\"\n",
    "    \n",
    "    simulator = MultiAgentCareerSimulator(API_KEY)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"🎯 MULTI-AGENT CAREER SIMULATION SYSTEM\")\n",
    "    print(\"   Powered by: Research → Design → Evaluate → Narrate Agents\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    career = input(\"\\n🎬 What career would you like to experience? \")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"🚀 AGENT COLLABORATION IN PROGRESS...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Multi-agent startup sequence\n",
    "    opening = simulator.start_simulation(career)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"📱 YOUR CAREER DAY BEGINS:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(opening)\n",
    "    \n",
    "    # Interactive loop with ReAct pattern\n",
    "    while simulator.simulation_state[\"scenarios_completed\"] < 5:\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        user_input = input(\"\\n💬 What do you do? (or 'quit' to end): \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'end']:\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"🤖 AGENTS PROCESSING YOUR DECISION...\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        response = simulator.process_user_decision(user_input)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"📱 WHAT HAPPENS NEXT:\")\n",
    "        print(\"=\" * 70)\n",
    "        print(response)\n",
    "    \n",
    "    # Generate multi-agent summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"🏆 CAREER DAY COMPLETE - GENERATING INSIGHTS...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    summary = simulator.generate_summary()\n",
    "    \n",
    "    print(f\"\\n📊 SUMMARY:\")\n",
    "    print(f\"   Career: {summary['career']}\")\n",
    "    print(f\"   Scenarios Completed: {summary['scenarios_completed']}\")\n",
    "    print(f\"   Skills Demonstrated: {', '.join(summary['skills'][:5])}\")\n",
    "    print(f\"   Agent Interactions: {summary['agent_interactions']}\")\n",
    "    print(f\"\\n{summary['summary']}\")\n",
    "    \n",
    "    # Show agent log (useful for hackathon demo)\n",
    "    print(f\"\\n🔍 Agent Collaboration Log: {len(simulator.get_agent_log())} interactions\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08dbda1-6e5e-40bf-8612-f0141f191533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
